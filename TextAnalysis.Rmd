---
title: "Data wrangling"
output: html_document
date: "2023-11-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readr)
library(tidytext)
library(textdata)
library(wordcloud)

library(ggrepel)
library(broom)
library(GGally)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r,message=FALSE}
data <- read_csv("data/survey_results_public.csv")

fdata <- data %>% filter(
  Country == "United States of America",
  SOVisitFreq == "Daily or almost daily"
)


saveRDS(data, "survey_results.rds")


df <- data |>
  select(ResponseId, SOAI, YearsCode, Age)

saveRDS(df, "data/ID_SOAI_responses.rds")

soai_res <- read_rds("data/ID_SOAI_responses.rds")

glimpse(soai_res)

soai_data <- soai_res |>
 unnest_tokens(output = word, input= SOAI, token="ngrams", n=3) %>%
  filter(!is.na(word))

non_stop_words <- c("necessary", "don't", "awfully", "appropriate", "wouldn't") # add more

more_stop_words <- c("stack", "overflow", "ai", "stackoverflow", "questions", "answers", "users","it could","would","would be")

# filter stop_words to keep some words

filtered_stop_words <- stop_words |>
  filter(!word %in% non_stop_words)


soai_no_stopwords <- soai_data |>
  anti_join(filtered_stop_words, by = "word") |>
  filter(! word %in% more_stop_words)

removed_words <- soai_data |>
  anti_join(soai_no_stopwords, by = "word") |>
  count(word) |>
  arrange(word)


soai_no_stopwords |>
    count(word, sort = TRUE) |>
    slice(1:30) |>
    # fct_reorder is used to re-order the axis (displaying the word)
    # by values of n (the number of times that word was used)
    ggplot(aes(x = fct_reorder(word, n), y = n, color = word, fill = word)) +
    geom_col() +
    # Rotate graph
    coord_flip() +
    guides(color = "none",
           fill = "none") +
    labs(
      # Remove x variable label; notice that although coordinates are flipped,
      # the labels correspond to which variables were specified
      # as `x` and `y` in `aes()`
      x = NULL,
      y = "Number of instances",
      title = "The most common words in developers responses on AI")

soai_word_freqs <- soai_no_stopwords |>
  select(word) |>
  count(word)
  
```


```
#######################
# CLUSTERING ANALYSIS #
#######################

# Join soai_affin with df to get total_score_per_response and other numeric variable
text_df <- merge(x=df,y=soai_afinn, 
             by="ResponseId")

# CLUSTER 

text_c1 <- text_df |>
  kmeans(centers = 5, nstart = 20)

text_c1 <- augment(text_c1, text_df)

# Visualize the cluster assignments and centroids
ggplot(ma_colleges_c2, aes(x = sat_math25, y = sat_readwrite25)) + 
  geom_point(aes(color = .cluster, shape = .cluster)) +
  geom_text_repel(aes(label = institution, color = .cluster), 
                  size = 3, max.overlaps = 15, show.legend = FALSE) +
  scale_x_continuous(breaks = scales::breaks_width(25)) +
  scale_y_continuous(breaks = scales::breaks_width(25)) +
  # Add centroid labels to plot
  geom_label(data = ma_kmeans2_summaries, aes(label = cluster, color = cluster),
             size = 3,
             label.r = unit(0.5, "lines"),
             label.size = 1.5,
             label.padding = unit(0.5, "lines"),
             show.legend = FALSE) +
  labs(x = "SAT Math\n(25th percentile)",
       y = "SAT Reading & Writing\n(25th percentile)",
       color = "Cluster",
       shape = "Cluster") +
  theme_classic()


```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
